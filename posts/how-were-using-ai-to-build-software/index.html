<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>How We&#39;re Using AI to Build Software (And Everything Else) | notes.spacebase.org</title>
<meta name="keywords" content="">
<meta name="description" content="A practical look at how AI is changing software development, from tools to workflows to the uncomfortable questions about what comes next.">
<meta name="author" content="Miguel Branco">
<link rel="canonical" href="https://notes.spacebase.org/posts/how-were-using-ai-to-build-software/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://notes.spacebase.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://notes.spacebase.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://notes.spacebase.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://notes.spacebase.org/apple-touch-icon.png">
<link rel="mask-icon" href="https://notes.spacebase.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://notes.spacebase.org/posts/how-were-using-ai-to-build-software/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "ba0363cc644f41eda2ace0d78e742f89"}'></script>
<meta property="og:url" content="https://notes.spacebase.org/posts/how-were-using-ai-to-build-software/">
  <meta property="og:site_name" content="notes.spacebase.org">
  <meta property="og:title" content="How We&#39;re Using AI to Build Software (And Everything Else)">
  <meta property="og:description" content="A practical look at how AI is changing software development, from tools to workflows to the uncomfortable questions about what comes next.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-06-15T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-06-15T00:00:00+00:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="How We&#39;re Using AI to Build Software (And Everything Else)">
<meta name="twitter:description" content="A practical look at how AI is changing software development, from tools to workflows to the uncomfortable questions about what comes next.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://notes.spacebase.org/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "How We're Using AI to Build Software (And Everything Else)",
      "item": "https://notes.spacebase.org/posts/how-were-using-ai-to-build-software/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "How We're Using AI to Build Software (And Everything Else)",
  "name": "How We\u0027re Using AI to Build Software (And Everything Else)",
  "description": "A practical look at how AI is changing software development, from tools to workflows to the uncomfortable questions about what comes next.",
  "keywords": [
    
  ],
  "articleBody": "To me, the real inflection point came at the end of May 2025.\nThat’s when Anthropic—the company founded by ex-OpenAI researchers—released Claude 4, a new family of large language models. For software development, it is said that the previous models produced errors in 30-40% of generated code. Claude 4 is rumoured to have dropped that to 6-10%. It certainly matches my own observations…\nThis drop is not yet another incremental improvement. To me, it’s a phase change. When your error rate drops by that much, it fundamentally changes what’s possible.\nLet me walk you through how we’re actually using these tools, what works, what doesn’t, and some uncomfortable truths about where this may be heading.\nUnderstanding the Context Problem The biggest misconception about AI coding assistants is treating them like search engines or autocomplete on steroids. They’re not. They’re more like hiring a brilliant engineer who knows everything about programming—every language, every framework, every pattern—but knows absolutely nothing about your company, your codebase, or what you did yesterday.\nAnd here’s the kicker: Every morning, that engineer wakes up with complete amnesia. They forget everything about your project, your discussions, your decisions. You’re starting from scratch every single day.\nOnce you truly understand this constraint, you can start working around it effectively. These models excel when you give them:\nNew codebases: No legacy to understand, no historical decisions to unpack Well-organized, modular code: Clear boundaries, obvious responsibilities Clear, detailed specifications: The more context upfront, the better the output They struggle desperately with:\nLarge, messy, undocumented codebases: The kind most of us actually work with… Domain-specific business logic: The weird rules that only make sense in your industry Remembering context across sessions: That brilliant solution from yesterday? Gone. However, in the right scenarios, it does work, and remarkably well. This understanding led us to a radical experimentation: try and rebuilt a 10-year-old software stack from scratch. And we did it, in under 3 weeks, using mostly Claude 4. Not a refactor. Not a cleanup, but a complete rebuild. And it worked because starting fresh is now often faster than trying to get an AI to understand a decade of accumulated complexity.\nOur Actual Development Workflow Let me break down the exact process we use, step by step.\nPhase 1: Initial Design with GPT-4o We start with OpenAI’s GPT-4o for the initial exploration phase. Why? Because it’s great at creative exploration and can access the web in real-time. We begin with rough ideas, maybe just a paragraph describing what we want to build.\nThe key is iteration. We go back and forth, refining the idea until we have a solid 1-2 page summary of an intended architecture. This might be an overall system design or a specific component. During this phase, we’re explicitly asking it to challenge our assumptions. One prompt we use often: “Be critical. Give me the best solution regardless of my abilities or current tech stack.”\nGPT-4o is particularly good at exploring alternative architectures we found. It can pull in recent developments, check what similar systems are doing, and suggest approaches you might not have considered. But we don’t just accept its first answer—we push back, ask for alternatives, demand justification.\nPhase 2: Validation with o3 and o3-pro Once we have a design we like, we switch to OpenAI’s o-models. These are better at logical reasoning and system-level thinking. We use them to:\nTest the logical consistency of our design Identify components we might have missed Challenge our fundamental assumptions Find potential failure modes This phase often reveals gaps. Maybe we forgot about some aspects of integratign and configuring authentication. Maybe our data flow doesn’t actually make sense. Maybe we don’t have an architecture that gives itself to easy backup, or requires complex monitoring. Or maybe we’re solving the wrong problem entirely, or using an “old software stack”. Better to find out now than after we’ve written 10,000 lines of code.\nPhase 3: Deep Research Before we commit to the design, we use ChatGPT’s Deep Research plugin for background checks. This isn’t casual Googling—it’s systematic validation:\nCompetitor analysis: Who else has solved this problem? How? Technology validation: Are our chosen tools still the best option? Pattern recognition: Are we unknowingly recreating something that already exists? This phase has saved us from several mistakes. Once, we were about to build a complex data transformation pipeline when Deep Research revealed that our target format already had a well-maintained open-source library (which we heard about, but didn’t quite pay attention to). Another time, it showed us that our chosen database would hit scaling limits.\nPhase 4: The Spec File Everything we’ve learned gets distilled into a single file at first: SPEC.md. This isn’t a casual document, but a the contract between us and the AI. We structure it carefully:\n# Project Name ## Overview [1-2 paragraphs of what we're building and why] ## Architecture [Clear description of major components and how they interact] ## Phase 0: Foundation [What needs to exist before we can start] ## Phase 1: Core Functionality [The minimum viable implementation] ## Phase 2: Enhancement [What makes it actually useful] [... and so on] The phases are crucial. They give the AI a roadmap, a sequence of smaller problems to solve rather than one overwhelming task.\nPhase 5: Implementation in Cursor Now comes the actual coding. We use Cursor, an IDE with native LLM integration. We experimented a bunch but settled in Cursor, at least for the time being. Cursor is not “just” a wrapper around LLMs, but an entire environment built around AI assistance. This is a fast-moving area, but we’re happy with Cursor at this point.\nWe start fresh. New project, clean directory. We paste our spec and let Claude guide the implementation, step-by-step. For anything non-trivial, we always enable MAX mode—it costs more but gives access to larger context windows and longer reasoning chains.\nThe process is highly interactive. Claude suggests code, we review it, ask for changes, push for better solutions. It’s not passive—it’s a conversation. And unlike human pair programming, Claude never gets tired, never gets annoyed when you ask it to refactor something for the fifth time.\nTool Selection: What We Use and Why Let me be specific about our tool choices, because the details matter.\nFor Thinking and Planning: GPT-4o: Our go-to for creative exploration and initial design. It’s fast, has web access, and excels at generating alternatives. When we need to explore “what if” scenarios or understand a new domain quickly, this is our starting point. In the future, o3 will probably just be enough, but we found the speed and exploration of 4o helpful.\no3 and o3-pro: These models “think” before they speak. They’re slower but much better at logical consistency. We use them to validate architectures, find edge cases, and ensure our designs actually make sense. Think of them as the senior architect who reviews your plans.\nDeep Research Plugin: Not glamorous, but invaluable. It prevents us from reinventing wheels or choosing deprecated technologies. One search here can save days of wasted effort, or find libraries or frameworks that are just what we need; we cannot possibly follow up everything out there.\nFor Coding: Claude 4 Sonnet: The workhorse. Fast, cost-effective, and good enough for 80% of tasks. When we’re iterating quickly or building straightforward features, Sonnet is our default.\nClaude 4 Opus: The heavy hitter. More expensive, requires MAX mode in Cursor, but capable of complex refactors and deep reasoning. When we’re doing architectural changes or need to understand intricate dependencies, Opus is worth every penny.\nCursor IDE: This isn’t optional for us anymore: the native integration means the AI sees your entire project context, understands your file structure, and can make changes across multiple files coherently.\nA crucial point: Always force model selection in Cursor; our default is Claude 4 Sonnet. Don’t let the system pick for you. Different models have different strengths, and the default isn’t always optimal for your specific task.\nThe Language Pragmatism Shift Here’s something that would have been heretical a year ago: We’ve largely stopped caring about programming languages.\nWe used to be a deeply polyglot team. Our codebase included Scala for the backend, Java for legacy services, Python for data processing, C/C++ for performance-critical components, and even Go for some plugins. We had strong opinions about when to use each language.\nNow? We often let the AI choose. And 90% of the time, it picks Python or JavaScript.\nWhy? Simple math. These models have been trained on billions of lines of Python code. They’ve probably seen every Python pattern, every common bug, every idiom a thousand times. For Scala? Maybe they’ve seen millions of lines. That’s a massive difference in training data.\nThe practical result: The Python code Claude generates is consistently better in our view than the Scala code. More direct code. Fewer bugs, less confusion, better idioms, more maintainable. So we adapt ourselves instead.\nThis isn’t about language wars but about leverage. If the AI writes better Python, and the AI is doing most of the writing, then we write Python. The productivity gain swamps any theoretical advantage of a “better” language.\nThe Legacy Code Dilemma Legacy code is where the AI dream meets reality. And reality is messy.\nRemember that brilliant engineer with amnesia? Now ask them to modify a 10-year-old codebase with:\nNo documentation Inconsistent patterns Business logic scattered across 50 files Dependencies on deprecated libraries That one critical function everyone’s afraid to touch The AI will struggle. It’ll make changes that break subtle invariants. It’ll miss critical side effects. It’ll confidently refactor something that looks redundant but is actually load-bearing, covering a less-known edge case.\nBut here’s the radical concept to consider: Rebuilding is now perhaps cheaper than refactoring?\nWhen you can generate a clean, modern implementation in days instead of months, the entire “refactor vs rebuild” calculation changes. Those careful incremental improvements or gradual modernization? Often slower than just starting over with a clear spec and an AI assistant.\nThis challenges fundamental assumptions about software development:\nCode reuse: Maybe less valuable when generation is cheap Platform investments: Do they pay off if you can build targeted solutions quickly? Technical debt: Still real, but the payment options have changed We’re not saying abandon all existing code; of course not. But we are saying the tradeoffs have shifted dramatically and hence, the calculus has to change.\nThe Cost Revolution Two costs have collapsed so dramatically that they’re changing how we think about software development.\nThe Cost of Experimentation We can now try 10 different architectural approaches in the time it used to take to carefully plan one; everything from a backend, Docker, Helm Charts, load generators, etc. Failed experiments are “cheap” — sometimes just a days of work. This changes everything about how we approach problems.\nBefore, we’d spend weeks in design discussions, carefully considering options, because implementation was expensive. Now? We just build prototypes. “I wonder if a event-sourced architecture would work better here?” Let’s find out. Shortly after, we have a first working prototype to evaluate.\nThis means:\nMore radical ideas actually get tested (not just discussed) Less attachment to first solutions (because trying another approach is cheap) Faster pivots when something isn’t working Real data from working prototypes instead of theoretical discussions The Cost of Platform Development We used to love platforms. The economics were compelling: Build once, sell many times, add features over time, create network effects and lock-in. Platforms were how you built defensible software businesses.\nBut when you can build targeted solutions in days instead of months, the platform advantage shrinks. We’re increasingly thinking of:\nNarrow, focused tools: Do one thing, do it well (Unix-way…) Purpose-built solutions: Exactly what this customer needs, nothing more. Spin a custom dashboard and UI, and that’s ok Less feature creep: Why add features that complicate the codebase? More “good enough” implementations: Perfect is the enemy of shipped This doesn’t mean platforms are dead. But it does mean the bar for “this should be a platform” is much higher. The economics have shifted from “build general solutions” to “build specific solutions quickly.”\nBeyond Code: AI in Everything Naturally, the same workflow that changed our coding also works for other parts of the business.\nMarketing content, business strategy, website design, documentation, competitor analysis - these can all follow the same pattern:\nExplore with GPT-4o Validate with o3 Research with Deep Research Create structured specs Execute with appropriate tools Take this blog post. It started as rough notes in GPT-4o. We validated the structure with o3 then refined the prose with Claude. The final markdown goes straight to GitHub, which triggered Hugo, the static site builder. No WordPress, no CMS, just markdown files and git.\nAt RAW Labs, we’re redesigning our entire information flow to be AI-friendly:\nDocuments are in markdown (easy for AI to parse and generate) Processes are documented as specs (clear instructions for AI to follow) Data is structured and accessible (via APIs or simple file formats) The more AI-friendly your systems, the more we can delegate; and delegation is the key to leverage.\nThe Human Question Let’s address what everyone’s thinking but few want to discuss directly: What happens to jobs?\nThe role of a software engineer is fundamentally changing. You’re becoming a manager of AI agents rather than a direct producer of code. The job now involves:\nProblem structuring: Breaking down complex problems into AI-solvable chunks Quality validation: Knowing what good looks like and ensuring the AI delivers it Iteration guidance: Directing the AI toward better solutions Judgment calls: Making decisions the AI can’t or shouldn’t make But let’s be honest. If someone’s primary mode of work is waiting for a ticket, implementing exactly what’s specified, and moving on to the next ticket—yes, an AI can eventually do that job. And probably will, soon.\nThis isn’t comfortable to say. People will lose jobs as entire categories of work are becoming automatable. Pretending otherwise doesn’t help anyone prepare for what’s coming. I am well aware of Jeavons’ Paradox: “When a resource becomes cheaper or more efficient to use, overall consumption of that resource often increases — not decreases.” This is often said to mean there will be more need for s/w developers than ever. I’m not sure I take that view; I do think the amount of software will dramatically increase (thanks in part to specialization and automation), but I don’t think that necessarily means more developers. In fact, like Dario Amodei, I do think there will be significant changes in the job market.\nThe question is: What work can’t be automated? What requires human judgment, creativity, taste, or responsibility? That’s where people need to move.\nThe Person Driving Matters At first, I thought these tools would level the playing field. After all, we now have access to “deep research”—the kind of architectural insight and pattern recognition that used to require years at places like Facebook, Google, or Microsoft. Suddenly, any developer could evaluate systems at that level. The knowledge gap seemed to shrink overnight.\nBut the reality is more nuanced. Today, the effectiveness of these tools still heavily depends on who is driving the process. A developer with high agency—someone who can juggle complexity, go deep when needed, and solve unfamiliar problems independently—can become 10x, 50x, or even 100x more productive. (Fake numbers, but you get the idea.) Meanwhile, someone who mostly “does the job,” sticks to one familiar stack, and waits to be trained or directed might see a much smaller boost—maybe 2x.\nThat variance isn’t just theoretical—it’s real, and it shows up quickly in team velocity.\nStrangely, this doesn’t make me pessimistic about younger or less experienced developers. Quite the opposite. A motivated newcomer today can build more projects and run more experiments in one year than some people could in a decade. They just have to care. If they show real interest, the learning curve is no longer steep—it’s a rocket.\nMulti-Agent Future We’re already seeing the next phase: multi-agent systems.\nA recent example: Someone used Claude’s API to create 6 specialized agents:\nProject Manager: Maintains task lists, coordinates other agents Product Requirements: Translates user needs into specifications UI Developer: Builds interfaces Backend Developer: Implements server logic Test Engineer: Writes and runs tests QA Analyst: Validates the entire system The PM agent coordinated the others, maintaining a TODO list and driving progress. Each agent had a specific role and communicated through structured interfaces.\nIs it flaky? Yes. Does it work for very simple projects today? Also yes.\nRemember: A lot of software work is simple and repetitive. Basic CRUD apps, simple integrations, standard features—these are what get automated first. And “flaky” is a temporary state. These systems improve exponentially, not linearly.\nThe Real Question We’re living through a step change in how software gets built. Not an improvement, not an evolution, but what may be a complete phase transition.\nThe old world had high costs for experimentation, strong advantages for platforms, and clear roles for human developers. The new world has cheap experiments, advantages for targeted solutions, and humans as orchestrators rather than implementors.\nWe can adopt early and help shape how this transformation plays out. We can influence how AI gets integrated, what practices emerge, and how the benefits get distributed. Or you can wait and adapt to a world shaped by others’ decisions.\nEither way, the old world isn’t coming back. The question isn’t whether to adapt, but how quickly and thoughtfully we can do so.\n",
  "wordCount" : "2907",
  "inLanguage": "en",
  "datePublished": "2025-06-15T00:00:00Z",
  "dateModified": "2025-06-15T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Miguel Branco"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://notes.spacebase.org/posts/how-were-using-ai-to-build-software/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "notes.spacebase.org",
    "logo": {
      "@type": "ImageObject",
      "url": "https://notes.spacebase.org/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://notes.spacebase.org/" accesskey="h" title="notes.spacebase.org (Alt + H)">notes.spacebase.org</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://notes.spacebase.org/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      How We&#39;re Using AI to Build Software (And Everything Else)
    </h1>
    <div class="post-description">
      A practical look at how AI is changing software development, from tools to workflows to the uncomfortable questions about what comes next.
    </div>
    <div class="post-meta"><span title='2025-06-15 00:00:00 +0000 UTC'>June 15, 2025</span>&nbsp;·&nbsp;14 min&nbsp;·&nbsp;Miguel Branco

</div>
  </header> 
  <div class="post-content"><p>To me, the real inflection point came at the end of May 2025.</p>
<p>That&rsquo;s when Anthropic—the company founded by ex-OpenAI researchers—released Claude 4, a new family of large language models. For software development, it is said that the previous models produced errors in 30-40% of generated code. Claude 4 is rumoured to have dropped that to 6-10%. It certainly matches my own observations&hellip;</p>
<p>This drop is not yet another incremental improvement. To me, it&rsquo;s a phase change. When your error rate drops by that much, it fundamentally changes what&rsquo;s possible.</p>
<p>Let me walk you through how we&rsquo;re actually using these tools, what works, what doesn&rsquo;t, and some uncomfortable truths about where this may be heading.</p>
<h2 id="understanding-the-context-problem">Understanding the Context Problem<a hidden class="anchor" aria-hidden="true" href="#understanding-the-context-problem">#</a></h2>
<p>The biggest misconception about AI coding assistants is treating them like search engines or autocomplete on steroids. They&rsquo;re not. They&rsquo;re more like hiring a brilliant engineer who knows everything about programming—every language, every framework, every pattern—but knows absolutely nothing about your company, your codebase, or what you did yesterday.</p>
<p>And here&rsquo;s the kicker: Every morning, that engineer wakes up with complete amnesia. They forget everything about your project, your discussions, your decisions. You&rsquo;re starting from scratch every single day.</p>
<p>Once you truly understand this constraint, you can start working around it effectively. These models excel when you give them:</p>
<ul>
<li><strong>New codebases</strong>: No legacy to understand, no historical decisions to unpack</li>
<li><strong>Well-organized, modular code</strong>: Clear boundaries, obvious responsibilities</li>
<li><strong>Clear, detailed specifications</strong>: The more context upfront, the better the output</li>
</ul>
<p>They struggle desperately with:</p>
<ul>
<li><strong>Large, messy, undocumented codebases</strong>: The kind most of us actually work with&hellip;</li>
<li><strong>Domain-specific business logic</strong>: The weird rules that only make sense in your industry</li>
<li><strong>Remembering context across sessions</strong>: That brilliant solution from yesterday? Gone.</li>
</ul>
<p>However, in the right scenarios, it <em>does work</em>, and remarkably well. This understanding led us to a radical experimentation: try and rebuilt a 10-year-old software stack from scratch. And we did it, in under 3 weeks, using mostly Claude 4. Not a refactor. Not a cleanup, but a complete rebuild. And it worked because starting fresh is now often faster than trying to get an AI to understand a decade of accumulated complexity.</p>
<h2 id="our-actual-development-workflow">Our Actual Development Workflow<a hidden class="anchor" aria-hidden="true" href="#our-actual-development-workflow">#</a></h2>
<p>Let me break down the exact process we use, step by step.</p>
<h3 id="phase-1-initial-design-with-gpt-4o">Phase 1: Initial Design with GPT-4o<a hidden class="anchor" aria-hidden="true" href="#phase-1-initial-design-with-gpt-4o">#</a></h3>
<p>We start with OpenAI&rsquo;s GPT-4o for the initial exploration phase. Why? Because it&rsquo;s great at creative exploration and can access the web in real-time. We begin with rough ideas, maybe just a paragraph describing what we want to build.</p>
<p>The key is iteration. We go back and forth, refining the idea until we have a solid 1-2 page summary of an intended architecture. This might be an overall system design or a specific component. During this phase, we&rsquo;re explicitly asking it to challenge our assumptions. One prompt we use often: &ldquo;Be critical. Give me the best solution regardless of my abilities or current tech stack.&rdquo;</p>
<p>GPT-4o is particularly good at exploring alternative architectures we found. It can pull in recent developments, check what similar systems are doing, and suggest approaches you might not have considered. But we don&rsquo;t just accept its first answer—we push back, ask for alternatives, demand justification.</p>
<h3 id="phase-2-validation-with-o3-and-o3-pro">Phase 2: Validation with o3 and o3-pro<a hidden class="anchor" aria-hidden="true" href="#phase-2-validation-with-o3-and-o3-pro">#</a></h3>
<p>Once we have a design we like, we switch to OpenAI&rsquo;s o-models. These are better at logical reasoning and system-level thinking. We use them to:</p>
<ul>
<li>Test the logical consistency of our design</li>
<li>Identify components we might have missed</li>
<li>Challenge our fundamental assumptions</li>
<li>Find potential failure modes</li>
</ul>
<p>This phase often reveals gaps. Maybe we forgot about some aspects of integratign and configuring authentication. Maybe our data flow doesn&rsquo;t actually make sense. Maybe we don&rsquo;t have an architecture that gives itself to easy backup, or requires complex monitoring. Or maybe we&rsquo;re solving the wrong problem entirely, or using an &ldquo;old software stack&rdquo;. Better to find out now than after we&rsquo;ve written 10,000 lines of code.</p>
<h3 id="phase-3-deep-research">Phase 3: Deep Research<a hidden class="anchor" aria-hidden="true" href="#phase-3-deep-research">#</a></h3>
<p>Before we commit to the design, we use ChatGPT&rsquo;s Deep Research plugin for background checks. This isn&rsquo;t casual Googling—it&rsquo;s systematic validation:</p>
<ul>
<li><strong>Competitor analysis</strong>: Who else has solved this problem? How?</li>
<li><strong>Technology validation</strong>: Are our chosen tools still the best option?</li>
<li><strong>Pattern recognition</strong>: Are we unknowingly recreating something that already exists?</li>
</ul>
<p>This phase has saved us from several mistakes. Once, we were about to build a complex data transformation pipeline when Deep Research revealed that our target format already had a well-maintained open-source library (which we heard about, but didn&rsquo;t quite pay attention to). Another time, it showed us that our chosen database would hit scaling limits.</p>
<h3 id="phase-4-the-spec-file">Phase 4: The Spec File<a hidden class="anchor" aria-hidden="true" href="#phase-4-the-spec-file">#</a></h3>
<p>Everything we&rsquo;ve learned gets distilled into a single file at first: <code>SPEC.md</code>. This isn&rsquo;t a casual document, but a the contract between us and the AI. We structure it carefully:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span># Project Name
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Overview
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>[1-2 paragraphs of what we&#39;re building and why]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Architecture
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>[Clear description of major components and how they interact]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Phase 0: Foundation
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>[What needs to exist before we can start]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Phase 1: Core Functionality
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>[The minimum viable implementation]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Phase 2: Enhancement
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>[What makes it actually useful]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>[... and so on]
</span></span></code></pre></div><p>The phases are crucial. They give the AI a roadmap, a sequence of smaller problems to solve rather than one overwhelming task.</p>
<h3 id="phase-5-implementation-in-cursor">Phase 5: Implementation in Cursor<a hidden class="anchor" aria-hidden="true" href="#phase-5-implementation-in-cursor">#</a></h3>
<p>Now comes the actual coding. We use Cursor, an IDE with native LLM integration. We experimented a bunch but settled in Cursor, at least for the time being. Cursor is not &ldquo;just&rdquo; a wrapper around LLMs, but an entire environment built around AI assistance. This is a fast-moving area, but we&rsquo;re happy with Cursor at this point.</p>
<p>We start fresh. New project, clean directory. We paste our spec and let Claude guide the implementation, step-by-step. For anything non-trivial, we always enable MAX mode—it costs more but gives access to larger context windows and longer reasoning chains.</p>
<p>The process is highly interactive. Claude suggests code, we review it, ask for changes, push for better solutions. It&rsquo;s not passive—it&rsquo;s a conversation. And unlike human pair programming, Claude never gets tired, never gets annoyed when you ask it to refactor something for the fifth time.</p>
<h2 id="tool-selection-what-we-use-and-why">Tool Selection: What We Use and Why<a hidden class="anchor" aria-hidden="true" href="#tool-selection-what-we-use-and-why">#</a></h2>
<p>Let me be specific about our tool choices, because the details matter.</p>
<h3 id="for-thinking-and-planning">For Thinking and Planning:<a hidden class="anchor" aria-hidden="true" href="#for-thinking-and-planning">#</a></h3>
<p><strong>GPT-4o</strong>: Our go-to for creative exploration and initial design. It&rsquo;s fast, has web access, and excels at generating alternatives. When we need to explore &ldquo;what if&rdquo; scenarios or understand a new domain quickly, this is our starting point. In the future, o3 will probably just be enough, but we found the speed and exploration of 4o helpful.</p>
<p><strong>o3 and o3-pro</strong>: These models &ldquo;think&rdquo; before they speak. They&rsquo;re slower but much better at logical consistency. We use them to validate architectures, find edge cases, and ensure our designs actually make sense. Think of them as the senior architect who reviews your plans.</p>
<p><strong>Deep Research Plugin</strong>: Not glamorous, but invaluable. It prevents us from reinventing wheels or choosing deprecated technologies. One search here can save days of wasted effort, or find libraries or frameworks that are just what we need; we cannot possibly follow up everything out there.</p>
<h3 id="for-coding">For Coding:<a hidden class="anchor" aria-hidden="true" href="#for-coding">#</a></h3>
<p><strong>Claude 4 Sonnet</strong>: The workhorse. Fast, cost-effective, and good enough for 80% of tasks. When we&rsquo;re iterating quickly or building straightforward features, Sonnet is our default.</p>
<p><strong>Claude 4 Opus</strong>: The heavy hitter. More expensive, requires MAX mode in Cursor, but capable of complex refactors and deep reasoning. When we&rsquo;re doing architectural changes or need to understand intricate dependencies, Opus is worth every penny.</p>
<p><strong>Cursor IDE</strong>: This isn&rsquo;t optional for us anymore: the native integration means the AI sees your entire project context, understands your file structure, and can make changes across multiple files coherently.</p>
<p>A crucial point: Always force model selection in Cursor; our default is Claude 4 Sonnet. Don&rsquo;t let the system pick for you. Different models have different strengths, and the default isn&rsquo;t always optimal for your specific task.</p>
<h2 id="the-language-pragmatism-shift">The Language Pragmatism Shift<a hidden class="anchor" aria-hidden="true" href="#the-language-pragmatism-shift">#</a></h2>
<p>Here&rsquo;s something that would have been heretical a year ago: We&rsquo;ve largely stopped caring about programming languages.</p>
<p>We used to be a deeply polyglot team. Our codebase included Scala for the backend, Java for legacy services, Python for data processing, C/C++ for performance-critical components, and even Go for some plugins. We had strong opinions about when to use each language.</p>
<p>Now? We often let the AI choose. And 90% of the time, it picks Python or JavaScript.</p>
<p>Why? Simple math. These models have been trained on billions of lines of Python code. They&rsquo;ve probably seen every Python pattern, every common bug, every idiom a thousand times. For Scala? Maybe they&rsquo;ve seen millions of lines. That&rsquo;s a massive difference in training data.</p>
<p>The practical result: The Python code Claude generates is consistently better in our view than the Scala code. More direct code. Fewer bugs, less confusion, better idioms, more maintainable. So we adapt ourselves instead.</p>
<p>This isn&rsquo;t about language wars but about leverage. If the AI writes better Python, and the AI is doing most of the writing, then we write Python. The productivity gain swamps any theoretical advantage of a &ldquo;better&rdquo; language.</p>
<h2 id="the-legacy-code-dilemma">The Legacy Code Dilemma<a hidden class="anchor" aria-hidden="true" href="#the-legacy-code-dilemma">#</a></h2>
<p>Legacy code is where the AI dream meets reality. And reality is messy.</p>
<p>Remember that brilliant engineer with amnesia? Now ask them to modify a 10-year-old codebase with:</p>
<ul>
<li>No documentation</li>
<li>Inconsistent patterns</li>
<li>Business logic scattered across 50 files</li>
<li>Dependencies on deprecated libraries</li>
<li>That one critical function everyone&rsquo;s afraid to touch</li>
</ul>
<p>The AI will struggle. It&rsquo;ll make changes that break subtle invariants. It&rsquo;ll miss critical side effects. It&rsquo;ll confidently refactor something that looks redundant but is actually load-bearing, covering a less-known edge case.</p>
<p>But here&rsquo;s the radical concept to consider: Rebuilding is now perhaps cheaper than refactoring?</p>
<p>When you can generate a clean, modern implementation in days instead of months, the entire &ldquo;refactor vs rebuild&rdquo; calculation changes. Those careful incremental improvements or gradual modernization? Often slower than just starting over with a clear spec and an AI assistant.</p>
<p>This challenges fundamental assumptions about software development:</p>
<ul>
<li><strong>Code reuse</strong>: Maybe less valuable when generation is cheap</li>
<li><strong>Platform investments</strong>: Do they pay off if you can build targeted solutions quickly?</li>
<li><strong>Technical debt</strong>: Still real, but the payment options have changed</li>
</ul>
<p>We&rsquo;re not saying abandon all existing code; of course not. But we are saying the tradeoffs have shifted dramatically and hence, the calculus has to change.</p>
<h2 id="the-cost-revolution">The Cost Revolution<a hidden class="anchor" aria-hidden="true" href="#the-cost-revolution">#</a></h2>
<p>Two costs have collapsed so dramatically that they&rsquo;re changing how we think about software development.</p>
<h3 id="the-cost-of-experimentation">The Cost of Experimentation<a hidden class="anchor" aria-hidden="true" href="#the-cost-of-experimentation">#</a></h3>
<p>We can now try 10 different architectural approaches in the time it used to take to carefully plan one; everything from a backend, Docker, Helm Charts, load generators, etc. Failed experiments are &ldquo;cheap&rdquo; — sometimes just a days of work. This changes everything about how we approach problems.</p>
<p>Before, we&rsquo;d spend weeks in design discussions, carefully considering options, because implementation was expensive. Now? We just build prototypes. &ldquo;I wonder if a event-sourced architecture would work better here?&rdquo; Let&rsquo;s find out. Shortly after, we have a first working prototype to evaluate.</p>
<p>This means:</p>
<ul>
<li>More radical ideas actually get tested (not just discussed)</li>
<li>Less attachment to first solutions (because trying another approach is cheap)</li>
<li>Faster pivots when something isn&rsquo;t working</li>
<li>Real data from working prototypes instead of theoretical discussions</li>
</ul>
<h3 id="the-cost-of-platform-development">The Cost of Platform Development<a hidden class="anchor" aria-hidden="true" href="#the-cost-of-platform-development">#</a></h3>
<p>We used to love platforms. The economics were compelling: Build once, sell many times, add features over time, create network effects and lock-in. Platforms were how you built defensible software businesses.</p>
<p>But when you can build targeted solutions in days instead of months, the platform advantage shrinks. We&rsquo;re increasingly thinking of:</p>
<ul>
<li><strong>Narrow, focused tools</strong>: Do one thing, do it well (Unix-way&hellip;)</li>
<li><strong>Purpose-built solutions</strong>: Exactly what this customer needs, nothing more. Spin a custom dashboard and UI, and that&rsquo;s ok</li>
<li><strong>Less feature creep</strong>: Why add features that complicate the codebase?</li>
<li><strong>More &ldquo;good enough&rdquo; implementations</strong>: Perfect is the enemy of shipped</li>
</ul>
<p>This doesn&rsquo;t mean platforms are dead. But it does mean the bar for &ldquo;this should be a platform&rdquo; is much higher. The economics have shifted from &ldquo;build general solutions&rdquo; to &ldquo;build specific solutions quickly.&rdquo;</p>
<h2 id="beyond-code-ai-in-everything">Beyond Code: AI in Everything<a hidden class="anchor" aria-hidden="true" href="#beyond-code-ai-in-everything">#</a></h2>
<p>Naturally, the same workflow that changed our coding also works for other parts of the business.</p>
<p>Marketing content, business strategy, website design, documentation, competitor analysis - these can all follow the same pattern:</p>
<ol>
<li>Explore with GPT-4o</li>
<li>Validate with o3</li>
<li>Research with Deep Research</li>
<li>Create structured specs</li>
<li>Execute with appropriate tools</li>
</ol>
<p>Take this blog post. It started as rough notes in GPT-4o. We validated the structure with o3 then refined the prose with Claude. The final markdown goes straight to GitHub, which triggered Hugo, the static site builder. No WordPress, no CMS, just markdown files and git.</p>
<p>At RAW Labs, we&rsquo;re redesigning our entire information flow to be AI-friendly:</p>
<ul>
<li>Documents are in markdown (easy for AI to parse and generate)</li>
<li>Processes are documented as specs (clear instructions for AI to follow)</li>
<li>Data is structured and accessible (via APIs or simple file formats)</li>
</ul>
<p>The more AI-friendly your systems, the more we can delegate; and delegation is the key to leverage.</p>
<h2 id="the-human-question">The Human Question<a hidden class="anchor" aria-hidden="true" href="#the-human-question">#</a></h2>
<p>Let&rsquo;s address what everyone&rsquo;s thinking but few want to discuss directly: What happens to jobs?</p>
<p>The role of a software engineer is fundamentally changing. You&rsquo;re becoming a manager of AI agents rather than a direct producer of code. The job now involves:</p>
<ul>
<li><strong>Problem structuring</strong>: Breaking down complex problems into AI-solvable chunks</li>
<li><strong>Quality validation</strong>: Knowing what good looks like and ensuring the AI delivers it</li>
<li><strong>Iteration guidance</strong>: Directing the AI toward better solutions</li>
<li><strong>Judgment calls</strong>: Making decisions the AI can&rsquo;t or shouldn&rsquo;t make</li>
</ul>
<p>But let&rsquo;s be honest. If someone&rsquo;s primary mode of work is waiting for a ticket, implementing exactly what&rsquo;s specified, and moving on to the next ticket—yes, an AI can eventually do that job. And probably will, soon.</p>
<p>This isn&rsquo;t comfortable to say. People will lose jobs as entire categories of work are becoming automatable. Pretending otherwise doesn&rsquo;t help anyone prepare for what&rsquo;s coming. I am well aware of Jeavons&rsquo; Paradox: &ldquo;When a resource becomes cheaper or more efficient to use, overall consumption of that resource often increases — not decreases.&rdquo; This is often said to mean there will be more need for s/w developers than ever. I&rsquo;m not sure I take that view; I do think the amount of software will dramatically increase (thanks in part to specialization and automation), but I don&rsquo;t think that necessarily means <em>more</em> developers. In fact, like Dario Amodei, I do think there will be significant changes in the job market.</p>
<p>The question is: What work can&rsquo;t be automated? What requires human judgment, creativity, taste, or responsibility? That&rsquo;s where people need to move.</p>
<h3 id="the-person-driving-matters">The Person Driving Matters<a hidden class="anchor" aria-hidden="true" href="#the-person-driving-matters">#</a></h3>
<p>At first, I thought these tools would level the playing field. After all, we now have access to “deep research”—the kind of architectural insight and pattern recognition that used to require years at places like Facebook, Google, or Microsoft. Suddenly, any developer could evaluate systems at that level. The knowledge gap seemed to shrink overnight.</p>
<p>But the reality is more nuanced. Today, the effectiveness of these tools still heavily depends on who is driving the process. A developer with high agency—someone who can juggle complexity, go deep when needed, and solve unfamiliar problems independently—can become 10x, 50x, or even 100x more productive. (Fake numbers, but you get the idea.) Meanwhile, someone who mostly “does the job,” sticks to one familiar stack, and waits to be trained or directed might see a much smaller boost—maybe 2x.</p>
<p>That variance isn’t just theoretical—it’s real, and it shows up quickly in team velocity.</p>
<p>Strangely, this doesn’t make me pessimistic about younger or less experienced developers. Quite the opposite. A motivated newcomer today can build more projects and run more experiments in one year than some people could in a decade. They just have to care. If they show real interest, the learning curve is no longer steep—it’s a rocket.</p>
<h2 id="multi-agent-future">Multi-Agent Future<a hidden class="anchor" aria-hidden="true" href="#multi-agent-future">#</a></h2>
<p>We&rsquo;re already seeing the next phase: multi-agent systems.</p>
<p>A recent example: Someone used Claude&rsquo;s API to create 6 specialized agents:</p>
<ul>
<li><strong>Project Manager</strong>: Maintains task lists, coordinates other agents</li>
<li><strong>Product Requirements</strong>: Translates user needs into specifications</li>
<li><strong>UI Developer</strong>: Builds interfaces</li>
<li><strong>Backend Developer</strong>: Implements server logic</li>
<li><strong>Test Engineer</strong>: Writes and runs tests</li>
<li><strong>QA Analyst</strong>: Validates the entire system</li>
</ul>
<p>The PM agent coordinated the others, maintaining a TODO list and driving progress. Each agent had a specific role and communicated through structured interfaces.</p>
<p>Is it flaky? Yes. Does it work for very simple projects today? Also yes.</p>
<p>Remember: A lot of software work is simple and repetitive. Basic CRUD apps, simple integrations, standard features—these are what get automated first. And &ldquo;flaky&rdquo; is a temporary state. These systems improve exponentially, not linearly.</p>
<h2 id="the-real-question">The Real Question<a hidden class="anchor" aria-hidden="true" href="#the-real-question">#</a></h2>
<p>We&rsquo;re living through a step change in how software gets built. Not an improvement, not an evolution, but what may be a complete phase transition.</p>
<p>The old world had high costs for experimentation, strong advantages for platforms, and clear roles for human developers. The new world has cheap experiments, advantages for targeted solutions, and humans as orchestrators rather than implementors.</p>
<p>We can adopt early and help shape how this transformation plays out. We can influence how AI gets integrated, what practices emerge, and how the benefits get distributed. Or you can wait and adapt to a world shaped by others&rsquo; decisions.</p>
<p>Either way, the old world isn&rsquo;t coming back. The question isn&rsquo;t whether to adapt, but how quickly and thoughtfully we can do so.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://notes.spacebase.org/">notes.spacebase.org</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
